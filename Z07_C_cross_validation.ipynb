{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Regresja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rozważmy zbiór Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\pythonProject5\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "boston = datasets.load_boston()\n",
    "# print description\n",
    "# print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the data\n",
    "boston_X = boston.data\n",
    "boston_Y = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podzielmy zbiór na część testową i treningową ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training/testing sets\n",
    "boston_X_train = boston_X[:-50]\n",
    "boston_X_test = boston_X[-50:]\n",
    " \n",
    "# Split the targets into training/testing sets\n",
    "boston_y_train = boston_Y[:-50]\n",
    "boston_y_test = boston_Y[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=boston_X_train\n",
    "y=boston_y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie\n",
    "Znajdż najleprzy model dzieląc na zbiór testowy i terningowy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "kfold = model_selection.KFold(n_splits=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "grid_1 = GridSearchCV(make_pipeline(PolynomialFeatures(degree=2), ElasticNet(alpha=1)),\n",
    "                    param_grid={'polynomialfeatures__degree': [i for i in range(15)],\n",
    "                    'elasticnet__alpha': [10**i for i in range(-10,10)]},\n",
    "                    cv=kfold,\n",
    "                    refit=True)\n",
    "grid_2 = GridSearchCV(make_pipeline(PolynomialFeatures(degree=2), Lasso(alpha=1)),\n",
    "                    param_grid={'polynomialfeatures__degree': [i for i in range(15)],\n",
    "                    'lasso__alpha': [10**i for i in range(-10,10)]},\n",
    "                    cv=kfold,\n",
    "                    refit=True)\n",
    "grid_3 = GridSearchCV(make_pipeline(PolynomialFeatures(degree=2), Ridge(alpha=1)),\n",
    "                    param_grid={'polynomialfeatures__degree': [i for i in range(15)],\n",
    "                    'ridge__alpha': [10**i for i in range(-10,10)]},\n",
    "                    cv=kfold,\n",
    "                    refit=True)\n",
    "grid_4 = GridSearchCV(make_pipeline(PolynomialFeatures(degree=2), LinearRegression()),\n",
    "                    param_grid={'polynomialfeatures__degree': [i for i in range(15)]},\n",
    "                    cv=kfold,\n",
    "                    refit=True)\n",
    "grid_1.fit(X, y)\n",
    "grid_2.fit(X, y)\n",
    "grid_3.fit(X, y)\n",
    "grid_4.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "grid_1.cv_results_['mean_test_score'].reshape(4, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.matshow(grid_1.cv_results_['mean_test_score'].reshape(4, -1),\n",
    "vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"elasticnet__alpha\")\n",
    "plt.ylabel(\"polynomialfeatures__degree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.matshow(grid_2.cv_results_['mean_test_score'].reshape(4, -1),\n",
    "vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"lasso_alpha\")\n",
    "plt.ylabel(\"polynomialfeatures__degree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.matshow(grid_3.cv_results_['mean_test_score'].reshape(4, -1),\n",
    "vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"ridge__alpha\")\n",
    "plt.ylabel(\"polynomialfeatures__degree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import  metrics\n",
    "\n",
    "X_test=boston_X_test\n",
    "y_test=boston_y_test\n",
    "\n",
    "models = []\n",
    "models.append(('ElasticNet', grid_1.best_estimator_))\n",
    "models.append(('Lasso', grid_2.best_estimator_))\n",
    "models.append(('Ridge', grid_3.best_estimator_))\n",
    "models.append(('LR', grid_4.best_estimator_))\n",
    "\n",
    "r2 = []\n",
    "explained_variance_score = []\n",
    "median_absolute_error = []\n",
    "mean_squared_error = []\n",
    "mean_absolute_error = []\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    print(\"R^2: {}\".format(metrics.r2_score(y_test, model.predict(X_test)) ))\n",
    "    print(\"Explained variance score: {}\".format( metrics.explained_variance_score(y_test, model.predict(X_test)) ))\n",
    "    print(\"Median absolute error: {}\".format( metrics.median_absolute_error(y_test, model.predict(X_test)) ))\n",
    "    print(\"Mean squared error: {}\".format( metrics.mean_squared_error(y_test, model.predict(X_test)) ))\n",
    "    print(\"Mean absolute errors: {}\".format(metrics.mean_absolute_error(y_test, model.predict(X_test)) ))\n",
    "    r2.append(metrics.r2_score(y_test, model.predict(X_test)))\n",
    "    explained_variance_score.append(metrics.explained_variance_score(y_test, model.predict(X_test)))\n",
    "    median_absolute_error.append( metrics.median_absolute_error(y_test, model.predict(X_test)))\n",
    "    mean_squared_error.append(metrics.mean_squared_error(y_test, model.predict(X_test)))\n",
    "    mean_absolute_error.append(metrics.mean_absolute_error(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = {'r2': r2, \n",
    "     'explained_variance_score': explained_variance_score, \n",
    "     'median_absolute_error': median_absolute_error,\n",
    "     'mean_squared_error' : mean_squared_error,\n",
    "     'mean_absolute_error' : mean_absolute_error,\n",
    "    }\n",
    "df = pd.DataFrame(data=d)\n",
    "df.insert(loc=0, column='Method', value=['ElasticNet','Lasso','Ridge','LR'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}